{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import json\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from requests.exceptions import Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL           = \"https://sandiego.nextrequest.com\"\n",
    "REQUESTS_TABLE_URL = \"https://sandiego.nextrequest.com/requests?requests_smart_listing[page]=\"\n",
    "REQUEST_PAGE_URL   = \"https://sandiego.nextrequest.com/requests\"\n",
    "PAGES_COUNT        = 682 # going past the last page just forwards back to the last one\n",
    "SUCCESS_CODE       = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictKeys(list_of_dicts):\n",
    "    try:\n",
    "        keys = set()\n",
    "        for _dict in list_of_dicts:\n",
    "            if (len(_dict) > 0):\n",
    "                for key in _dict.keys():\n",
    "                    keys.add(key)\n",
    "        return keys\n",
    "    except:\n",
    "        logging.error(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_empty_space(string):\n",
    "    return \" \".join(string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rpage_data(pra_link, failed={}):\n",
    "    try:\n",
    "        r_data_i = {}\n",
    "        \n",
    "        r_page = BeautifulSoup(requests.get(BASE_URL + pra_link).text)\n",
    "        \n",
    "        \n",
    "        r_id = pra_link.split(\"/\")[-1]\n",
    "\n",
    "        r_text = clean_empty_space(r_page.find(\"div\", {\"id\": \"request-text\"}).get_text())\n",
    "    \n",
    "        r_date = r_page.findAll(\"p\", {\"class\": \"request_date\"})[0].get_text() # get the submission date\n",
    "        r_date = r_date.split()\n",
    "        r_channel = r_date[-1]\n",
    "        r_date = \" \".join(r_date[:3])\n",
    "        \n",
    "        r_department = r_page.findAll(\"p\", {\"class\": \"current-department\"})[0].get_text() # get the respective department\n",
    "        r_department = clean_empty_space(r_department)\n",
    "        r_contact = ' '.join(r_page.findAll(\"div\", {\"class\": \"staff-details\"})[0].text.split(\"Contact\",1)[1].split()) # get the request contact\n",
    "        \n",
    "        r_events = r_page.findAll(\"div\", {\"class\": \"generic-event\"}) # get each public event\n",
    "        r_events.reverse()\n",
    "        for event in r_events:\n",
    "            event_title = event.findAll(\"div\", {\"class\": \"event-title\"})[0].text\n",
    "            event_text  = event.findAll(\"div\", {\"class\": \"event-item\"})[0].text\n",
    "            event_title = ' '.join(event_title.split())\n",
    "            event_text  = ' '.join(event_text.split())\n",
    "            if (event_title == \"Request Closed Public\"):\n",
    "                r_data_i[\"Close_Date\"] = event_title + \" \" + \" \".join(event.findAll(\"div\")[-1].get_text().split()[:3]).replace(\",\",\"\")\n",
    "            if(~(event_title in r_data_i.keys())):\n",
    "                r_data_i[event_title] = event_text\n",
    "            else:\n",
    "                r_data_i[event_title] = r_data_i[event_title] + \"<NEXT> \" + event_text\n",
    "        \n",
    "        row = [r_id, r_text, r_date, r_channel, r_department, r_contact, r_data_i]\n",
    "        sleep(1)\n",
    "        return row\n",
    "    except:\n",
    "        logging.error(\"This request returned an error: \" + pra_link + \": \" + str(sys.exc_info()[0]))\n",
    "        failed[pra_link] = sys.exc_info()[0]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictKeys(list_of_dicts):\n",
    "    keys = set()\n",
    "    for _dict in list_of_dicts:\n",
    "        if (len(_dict) > 0):\n",
    "            for key in _dict[-1].keys():\n",
    "                keys.add(key)\n",
    "    return keys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code Below\n",
    "\n",
    "This pull was last run at 2p.m. Monday November 25, 2019. Around 17,000 public records request IDs acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pra_ids = []\n",
    "for i in range(1,PAGES_COUNT):\n",
    "    page_request = requests.get(REQUESTS_TABLE_URL + str(i))\n",
    "    \n",
    "    if page_request.status_code != SUCCESS_CODE:\n",
    "        logging.warning(\"FAILED CODE \" + str(page_request.status_code) + \"FOR PAGE \" + REQUESTS_TABLE_URL + str(i))\n",
    "        \n",
    "    if (i % 100 == 0):\n",
    "        print(str(i) + \" PAGES COMPLETED\")\n",
    "        #logging.info()\n",
    "        \n",
    "    page_text = BeautifulSoup(page_request.text)\n",
    "\n",
    "    request_table = page_text.find_all(\"table\", class_=\"request_table\")[0]\n",
    "    \n",
    "    for row in request_table.tbody.findAll('tr'):\n",
    "        pra_ids.append(row.findAll('td')[0].a.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_request = requests.get(REQUESTS_TABLE_URL + str(680))\n",
    "\n",
    "if page_request.status_code != SUCCESS_CODE:\n",
    "    logging.warning(\"FAILED CODE \" + str(page_request.status_code) + \"FOR PAGE \" + REQUESTS_TABLE_URL + str(i))\n",
    "    \n",
    "if (i % 100 == 0):\n",
    "    print(str(i) + \" PAGES COMPLETED\")\n",
    "    #logging.info()\n",
    "    \n",
    "page_text = BeautifulSoup(page_request.text)\n",
    "\n",
    "request_table = page_text.find_all(\"table\", class_=\"request_table\")[0]\n",
    "\n",
    "for row in request_table.tbody.findAll('tr'):\n",
    "    pra_ids.append(row.findAll('td')[0].a.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pra_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('pra_href_scrape.txt', 'w') as outfile:\n",
    "#    json.dump(pra_ids, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Request Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE REQUEST IDs\n",
    "with open('pra_href_scrape.txt') as json_file:\n",
    "    pra_ids = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_page = BeautifulSoup(requests.get(REQUEST_PAGE_URL + '/19-5666').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_requests = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_get_rpage_data('/requests/18-45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [get_rpage_data(link) for link in [\"/requests/18-1212\",\"/requests/16-1697\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "[corpus.append(get_rpage_data(link)) for link in pra_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [c for c in corpus if len(c) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pra_data.txt', 'w') as outfile:\n",
    "    json.dump(corpus, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_requests_dict = {r_id: str(_type) for (r_id, _type) in zip(failed_requests.keys(), failed_requests.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('failed_pulls_00.txt', 'w') as outfile:\n",
    "#    json.dump(failed_requests_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE FAILED SCRAPES\n",
    "with open('failed_pulls_00.txt') as json_file:\n",
    "    failed_requests = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_failed = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_requests = [get_rpage_data(pra_link, new_failed) for pra_link in failed_requests.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('failed_pulls_success.txt', 'w') as outfile:\n",
    "#    json.dump(success_requests, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE FAILED SCRAPES\n",
    "with open('pra_data.txt') as json_file:\n",
    "    corpus = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE FAILED SCRAPES\n",
    "with open('failed_pulls_success.txt') as json_file:\n",
    "    corpus01 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [c for c in corpus if len(c) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ in and append the newly acquired request\n",
    "corpus.extend(corpus01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('pra_fulldata.txt', 'w') as outfile:\n",
    "#    json.dump(corpus, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dicts = [c[-1] for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_names = getDictKeys(_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(event_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I need to expand each entry into its row representaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"r_id\", \"r_text\", \"date_submitted\", \"submission_method\", \"receiving_department\", \"assigned_pro\"] + list(event_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_row(row, col_names):\n",
    "    new_row = {k:np.nan for k in col_names}\n",
    "    new_row['r_id']                 = row[0]\n",
    "    new_row['r_text']               = row[1]\n",
    "    new_row['date_submitted']       = row[2]\n",
    "    new_row['submission_method']    = row[3]\n",
    "    new_row['receiving_department'] = row[4]\n",
    "    new_row['assigned_pro']         = row[5]\n",
    "    for key in row[6].keys():\n",
    "        new_row[key] = row[6][key]\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [expand_row(request, col_names) for request in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"raw_request_corpus.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw_request_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_release_cols = [\"Document(s) Released Public\", \"Document(s) Released Details Public\", \"Document(s) Released to Requester Details Public\", \"Document(s) Released to Requester Public\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(np.where(~((df[\"Document(s) Released Public\"].isnull()) & (df[\"Document(s) Released Details Public\"].isnull()) & (df[\"Document(s) Released to Requester Details Public\"].isnull()) & (df[\"Document(s) Released to Requester Public\"].isnull())), 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"doc_released\"] = np.where(~((df[\"Document(s) Released Public\"].isnull()) & (df[\"Document(s) Released Details Public\"].isnull()) & (df[\"Document(s) Released to Requester Details Public\"].isnull()) & (df[\"Document(s) Released to Requester Public\"].isnull())), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [x.lower().replace(\" \", \"_\").replace(\"_public\", \"\").replace(\"(\", \"\").replace(\")\", \"\") for x in list(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"processed_request_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
