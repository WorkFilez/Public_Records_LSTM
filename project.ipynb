{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "import json\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from requests.exceptions import Timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL           = \"https://sandiego.nextrequest.com\"\n",
    "REQUESTS_TABLE_URL = \"https://sandiego.nextrequest.com/requests?requests_smart_listing[page]=\"\n",
    "REQUEST_PAGE_URL   = \"https://sandiego.nextrequest.com/requests\"\n",
    "PAGES_COUNT        = 682 # going past the last page just forwards back to the last one\n",
    "SUCCESS_CODE       = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictKeys(list_of_dicts):\n",
    "    try:\n",
    "        keys = set()\n",
    "        for _dict in list_of_dicts:\n",
    "            if (len(_dict) > 0):\n",
    "                for key in _dict.keys():\n",
    "                    keys.add(key)\n",
    "        return keys\n",
    "    except:\n",
    "        logging.error(_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_empty_space(string):\n",
    "    return \" \".join(string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rpage_data(pra_link, failed={}):\n",
    "    try:\n",
    "        r_data_i = {}\n",
    "        \n",
    "        r_page = BeautifulSoup(requests.get(BASE_URL + pra_link).text)\n",
    "        \n",
    "        \n",
    "        r_id = pra_link.split(\"/\")[-1]\n",
    "\n",
    "        r_text = clean_empty_space(r_page.find(\"div\", {\"id\": \"request-text\"}).get_text())\n",
    "    \n",
    "        r_date = r_page.findAll(\"p\", {\"class\": \"request_date\"})[0].get_text() # get the submission date\n",
    "        r_date = r_date.split()\n",
    "        r_channel = r_date[-1]\n",
    "        r_date = \" \".join(r_date[:3])\n",
    "        \n",
    "        r_department = r_page.findAll(\"p\", {\"class\": \"current-department\"})[0].get_text() # get the respective department\n",
    "        r_department = clean_empty_space(r_department)\n",
    "        r_contact = ' '.join(r_page.findAll(\"div\", {\"class\": \"staff-details\"})[0].text.split(\"Contact\",1)[1].split()) # get the request contact\n",
    "        \n",
    "        r_events = r_page.findAll(\"div\", {\"class\": \"generic-event\"}) # get each public event\n",
    "        r_events.reverse()\n",
    "        for event in r_events:\n",
    "            event_title = event.findAll(\"div\", {\"class\": \"event-title\"})[0].text\n",
    "            event_text  = event.findAll(\"div\", {\"class\": \"event-item\"})[0].text\n",
    "            event_title = ' '.join(event_title.split())\n",
    "            event_text  = ' '.join(event_text.split())\n",
    "            if (event_title == \"Request Closed Public\"):\n",
    "                r_data_i[\"Close_Date\"] = event_title + \" \" + \" \".join(event.findAll(\"div\")[-1].get_text().split()[:3]).replace(\",\",\"\")\n",
    "            if(~(event_title in r_data_i.keys())):\n",
    "                r_data_i[event_title] = event_text\n",
    "            else:\n",
    "                r_data_i[event_title] = r_data_i[event_title] + \"<NEXT> \" + event_text\n",
    "        \n",
    "        row = [r_id, r_date, r_channel, r_department, r_contact, r_data_i]\n",
    "        sleep(1)\n",
    "        return row\n",
    "    except:\n",
    "        logging.error(\"This request returned an error: \" + pra_link + \": \" + str(sys.exc_info()[0]))\n",
    "        failed[pra_link] = sys.exc_info()[0]\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDictKeys(list_of_dicts):\n",
    "    keys = set()\n",
    "    for _dict in list_of_dicts:\n",
    "        if (len(_dict) > 0):\n",
    "            for key in _dict[-1].keys():\n",
    "                keys.add(key)\n",
    "    return keys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code Below\n",
    "\n",
    "This pull was last run at 2p.m. Monday November 25, 2019. Around 17,000 public records request IDs acquired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pra_ids = []\n",
    "for i in range(1,PAGES_COUNT):\n",
    "    page_request = requests.get(REQUESTS_TABLE_URL + str(i))\n",
    "    \n",
    "    if page_request.status_code != SUCCESS_CODE:\n",
    "        logging.warning(\"FAILED CODE \" + str(page_request.status_code) + \"FOR PAGE \" + REQUESTS_TABLE_URL + str(i))\n",
    "        \n",
    "    if (i % 100 == 0):\n",
    "        print(str(i) + \" PAGES COMPLETED\")\n",
    "        #logging.info()\n",
    "        \n",
    "    page_text = BeautifulSoup(page_request.text)\n",
    "\n",
    "    request_table = page_text.find_all(\"table\", class_=\"request_table\")[0]\n",
    "    \n",
    "    for row in request_table.tbody.findAll('tr'):\n",
    "        pra_ids.append(row.findAll('td')[0].a.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_request = requests.get(REQUESTS_TABLE_URL + str(680))\n",
    "\n",
    "if page_request.status_code != SUCCESS_CODE:\n",
    "    logging.warning(\"FAILED CODE \" + str(page_request.status_code) + \"FOR PAGE \" + REQUESTS_TABLE_URL + str(i))\n",
    "    \n",
    "if (i % 100 == 0):\n",
    "    print(str(i) + \" PAGES COMPLETED\")\n",
    "    #logging.info()\n",
    "    \n",
    "page_text = BeautifulSoup(page_request.text)\n",
    "\n",
    "request_table = page_text.find_all(\"table\", class_=\"request_table\")[0]\n",
    "\n",
    "for row in request_table.tbody.findAll('tr'):\n",
    "    pra_ids.append(row.findAll('td')[0].a.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pra_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('pra_href_scrape.txt', 'w') as outfile:\n",
    "#    json.dump(pra_ids, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Request Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE REQUEST IDs\n",
    "with open('pra_href_scrape.txt') as json_file:\n",
    "    pra_ids = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_page = BeautifulSoup(requests.get(REQUEST_PAGE_URL + '/19-5666').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_requests = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_get_rpage_data('/requests/18-45')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[corpus.append(get_rpage_data(link)) for link in pra_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(failed_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('pra_data.txt', 'w') as outfile:\n",
    "#    json.dump(corpus, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_requests_dict = {r_id: str(_type) for (r_id, _type) in zip(failed_requests.keys(), failed_requests.values())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('failed_pulls_00.txt', 'w') as outfile:\n",
    "#    json.dump(failed_requests_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE FAILED SCRAPES\n",
    "with open('failed_pulls_00.txt') as json_file:\n",
    "    failed_requests = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_failed = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_requests = [get_rpage_data(pra_link, new_failed) for pra_link in failed_requests.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('failed_pulls_success.txt', 'w') as outfile:\n",
    "#    json.dump(success_requests, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE FAILED SCRAPES\n",
    "with open('pra_data.txt') as json_file:\n",
    "    corpus = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE FAILED SCRAPES\n",
    "with open('failed_pulls_success.txt') as json_file:\n",
    "    corpus01 = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [c for c in corpus if len(c) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ in and append the newly acquired request\n",
    "corpus.extend(corpus01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('pra_fulldata.txt', 'w') as outfile:\n",
    "#    json.dump(corpus, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dicts = [c[-1] for c in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_names = getDictKeys(_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(event_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Document(s) Released Public', 'Request Closed Public', 'Department Assignment Details Public', 'Request Opened Public', 'Document(s) Released Details Public', 'Document(s) Released to Requester Details Public', 'Request Reopened Public', 'Document(s) Released to Requester Public', 'Request Closed Hide Public', 'Request Published Public', 'Close_Date', 'Department Assignment Public'}\n"
     ]
    }
   ],
   "source": [
    "print(event_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, I need to expand each entry into its row representaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19-5556',\n",
       " 'November 18, 2019',\n",
       " 'email',\n",
       " 'Public Records Administration',\n",
       " 'Angela Laurita',\n",
       " {'Request Opened Public': 'Request received via email',\n",
       "  'Department Assignment Public': 'Public Records Administration',\n",
       "  'Document(s) Released Public': 'General Application.pdf',\n",
       "  'Close_Date': 'Request Closed Public November 18 2019',\n",
       "  'Request Closed Public': '02. Released All responsive documents have been released pursuant to the California Public Records Act.',\n",
       "  'Request Published Public': ''}]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"r_id\", \"date_submitted\", \"submission_method\", \"receiving_department\", \"assigned_pro\"] + list(event_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r_id',\n",
       " 'date_submitted',\n",
       " 'submission_method',\n",
       " 'receiving_department',\n",
       " 'assigned_pro',\n",
       " 'Document(s) Released Public',\n",
       " 'Request Closed Public',\n",
       " 'Department Assignment Details Public',\n",
       " 'Request Opened Public',\n",
       " 'Document(s) Released Details Public',\n",
       " 'Document(s) Released to Requester Details Public',\n",
       " 'Request Reopened Public',\n",
       " 'Document(s) Released to Requester Public',\n",
       " 'Request Closed Hide Public',\n",
       " 'Request Published Public',\n",
       " 'Close_Date',\n",
       " 'Department Assignment Public']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_row(row, col_names):\n",
    "    new_row = {k:np.nan for k in col_names}\n",
    "    new_row['r_id'] = row[0]\n",
    "    new_row['date_submitted'] = row[1]\n",
    "    new_row['submission_method'] = row[2]\n",
    "    new_row['receiving_department'] = row[3]\n",
    "    new_row['assigned_pro'] = row[4]\n",
    "    for key in row[5].keys():\n",
    "        new_row[key] = row[5][key]\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [expand_row(request, col_names) for request in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"request_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
